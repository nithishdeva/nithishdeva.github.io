\documentclass[10pt]{article}
\usepackage[subpreambles=true]{standalone}
\usepackage{amsmath,amssymb}
\usepackage{hyperref}
\usepackage{import}

\title{A different way to derive Backprop}
\author{Nithish Divakar}
\date{v0.0.001}

\begin{document}
\maketitle
\tableofcontents
\section{How do you solve a constrained optimisation problem?}
Let our problem be.
$$\begin{aligned}
&\min f(x)
\\
s.t~& g_i(x) = 0
\end{aligned}$$
Let us begin by stating a fact. We will call this fact as Fact1

\begin{center}
\textbf{Fact1}: \textit{Gradient of a function gives direction which changes (increases) the function. Hence, directions perpendicular to gradient does not change the function's value.}
\end{center}


Now, if I say that a particular point, $\ddot{x}$ is a solution (possibly one of many) of the problem, then, $\ddot{x}$ must satisfy all constraints, i.e. $g_i(\ddot{x}) = 0$ and $f(\ddot{x})$ must not decrease without violating any constraints. 

If $S = \operatorname{span}(\nabla g_1(\ddot{x}),\ldots, \nabla g_n(\ddot{x}))$, then moving $\ddot{x}$ in any direction in $S$ will change one or more of the $g$'s. Reason: \textbf{Fact1}. We don't want any g's to change. We want them to be 0. So we can only move $\ddot{x}$ in $S^{\perp}$.

Now $-\nabla f(\ddot{x})$ is a direction to change (decrease) $f$. But, if $\ddot{x}$ was to be a solution, if $f$ can be decreased without violating any constraints, then $\ddot{x}$ is not solution. We can just move in that direction and decrease $f$ further. So, direction $-\nabla f(\ddot{x})$ should not be in $S^{\perp}$. Which, means $-\nabla f(\ddot{x}) \in S$. 

Since space spanned by a set of vectors is linear combination of all those vectors, we have

$$\begin{aligned}
\nabla f(\ddot{x}) = \sum \lambda_i \nabla g_i(\ddot{x})
\end{aligned}$$

All the points which satisfy the last equation are candidates for solution. Hence, the condition is necessary condition for a point to be solution. 

For a constrained optimisation problem like the one we are talking about, there is a particular function called Lagrangian. 


$$\begin{aligned}
L(x,\lambda) =  f(x) - \sum \lambda_i g_i(\ddot{x})
\end{aligned}$$

Lagrangian is particularly useful because, its saddle points numerates all the solution points of the original constrained optimisation problem.

$$\begin{aligned}
\nabla_x L=0 &\implies \nabla f(x) - \sum \lambda_i \nabla g_i(x) = 0
\\
\nabla_{\lambda_i} L=0 &\implies g_i(x)=0
\end{aligned}$$

So, \textbf{to solve a optimisation problem with equality constraints, find saddle points of its Lagrangian.}

\section{A particular constrained optimisation problem}
Lets take a look at the following problem. 
$$\begin{aligned}
\min z_n
\\
z_i &= f_i(z_{a(i)})
\end{aligned}$$

Its Lagrangian is

$$\begin{aligned}
L(z,\lambda) = z_n - \sum_i \lambda_i (z_i - f_i)
\end{aligned}$$


$$\begin{aligned}
\nabla_{\lambda_i} L = 0 &\implies&      z_i  &= f_i(z_{a(i)})
\\  
\nabla_{z_n}       L = 0 &\implies& \lambda_n &= 1
\\
\nabla_{z_i}       L = 0 &\implies& \lambda_i &= \sum_{k \in b(i)} \lambda_k \frac{\partial f_k}{\partial z_k}
\end{aligned}$$
So we have

\section{What is so special about this problem?}
What if I tell you we just derived back prop in previous derivations? Let me show you.

$$\begin{aligned}
z_{1} &= x\\
z_{2} &= y\\
z_{3} &= w_{1}\\
z_{4} &= b_{1}\\
z_{5} &= w_{2}\\
z_{6} &= b_{2}\\
\\
z_{7} &= z_{3}*z_{2} &&= w_{1}*x\\
z_{8} &= z_{7}z_{4} &&= w_{1}x+b_{1}\\
z_{9} &= relu(z_{8}) &&= relu(w_{1}x+b_{1})=a_{1}\\
\\
z_{10} &= z_{3}*z_{9} &&= w_{2}*a_{1}\\
z_{11} &= z_{10}+z_{6} &&= w_{2}a_{1}+b_{2}\\
z_{12} &= softmax(z_{11}) &&= softmax(w_{2}a_{1}+b_{2})\\
z_{13} &= loss(z_{12},z_{2})\\
\end{aligned}$$
This is  a 2 layer neural network and training step is essentially to minimise $z_{13}$.

The neural network formulation nicely fits into our earlier constrained optimisation problem. Earlier $z$'s are just inputs and parameters while later $z$'s are intermediate values in the forward computation. Lets look at what the legrangian is giving us.

\end{document}
