@article{Yang et al. 2019,
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1902.08129},
  year={2019},
  url={https://arxiv.org/pdf/1902.08129}
}

@article{Santurkar et al. (2018),
  title={How does batch normalization help optimization?},
  author={Santurkar, Shibani and Tsipras, Dimitris and Ilyas, Andrew and Madry, Aleksander},
  journal={Advances in neural information processing systems},
  volume={31},
  year={2018},
  url={https://arxiv.org/pdf/1805.11604.pdf}
}

@online{Doe:2009:Online,
  author = {Doe, Ringo},
  title = {This is a test entry of type {@ONLINE}},
  month = jun,
  year = {2009},
  url = {http://www.test.org/doe/},
  note = "[accessed 19-July-2008]"
}

@article{Blei et al. (2017),
  title={Variational inference: A review for statisticians},
  author={Blei, David M and Kucukelbir, Alp and McAuliffe, Jon D},
  journal={Journal of the American statistical Association},
  volume={112},
  number={518},
  pages={859--877},
  year={2017},
  publisher={Taylor \& Francis},
  url={https://arxiv.org/abs/1601.00670}
}
    
@article{Ho et al. (2020),
  title={Denoising diffusion probabilistic models},
  author={Ho, Jonathan and Jain, Ajay and Abbeel, Pieter},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={6840--6851},
  year={2020},
  url={https://arxiv.org/pdf/2006.11239.pdf}
}
    
@article{Ioffe et al. (2015),
  title={Batch normalization: Accelerating deep network training by reducing internal covariate shift},
  author={Ioffe, Sergey and Szegedy, Christian},
  booktitle={International conference on machine learning},
  pages={448--456},
  year={2015},
  organization={pmlr},
  url={http://proceedings.mlr.press/v37/ioffe15.pdf},
}

@article{Kingma et al. (2013),
  title={Auto-encoding variational bayes},
  author={Kingma, Diederik P and Welling, Max},
  journal={arXiv preprint arXiv:1312.6114},
  year={2013},
  url={https://arxiv.org/abs/1312.6114},
}
    
@article{Kingma et al. (2019),
  title={An introduction to variational autoencoders},
  author={Kingma, Diederik P and Welling, Max and others},
  journal={Foundations and Trends in Machine Learning},
  volume={12},
  number={4},
  pages={307--392},
  year={2019},
  publisher={Now Publishers, Inc.},
  url={https://arxiv.org/pdf/1906.02691.pdf},
}
    
@article{Lei Ba et al. (2016),
  title={Layer normalization},
  author={Ba, Jimmy Lei and Kiros, Jamie Ryan and Hinton, Geoffrey E},
  journal={arXiv preprint arXiv:1607.06450},
  year={2016}, 
  url={https://arxiv.org/abs/1607.06450},
}

@article{Luo et al. (2018),
  title={Differentiable learning-to-normalize via switchable normalization},
  author={Luo, Ping and Ren, Jiamin and Peng, Zhanglin and Zhang, Ruimao and Li, Jingyu},
  journal={arXiv preprint arXiv:1806.10779},
  year={2018},
  url={https://arxiv.org/abs/1806.10779},
}
    
@article{Miyato et al. (2018),
  title={Spectral normalization for generative adversarial networks},
  author={Miyato, Takeru and Kataoka, Toshiki and Koyama, Masanori and Yoshida, Yuichi},
  journal={arXiv preprint arXiv:1802.05957},
  year={2018},
  url={https://arxiv.org/pdf/1802.05957.pdf},
}

@inproceedings{Ranganath et al. (2014),
  title={Black box variational inference},
  author={Ranganath, Rajesh and Gerrish, Sean and Blei, David},
  booktitle={Artificial intelligence and statistics},
  pages={814--822},
  year={2014},
  organization={PMLR},
  url={http://www.cs.columbia.edu/~blei/papers/RanganathGerrishBlei2014.pdf},
}
    
@article{Rezende et al. (2014),
  title={Stochastic backpropagation and approximate inference in deep generative models.},
  url={https://arxiv.org/pdf/1401.4082.pdf},
}
    
@article{Ruiz et al. (2016),
  title={The generalized reparameterization gradient},
  author={Ruiz, Francisco R and AUEB, Titsias RC and Blei, David and others},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={http://www.cs.columbia.edu/~blei/papers/RuizTitsiasBlei2016b.pdf},
}
    
@article{Salimans et al. (2016),
  title={Weight normalization: A simple reparameterization to accelerate training of deep neural networks},
  author={Salimans, Tim and Kingma, Durk P},
  journal={Advances in neural information processing systems},
  volume={29},
  year={2016},
  url={https://arxiv.org/pdf/1602.07868.pdf},
}   

@article{Sohl-Dickstein et al. (2015),
  title={Deep unsupervised learning using nonequilibrium thermodynamics.},
  url={https://arxiv.org/pdf/1503.03585.pdf},
}
    
@article{Song et al. (2019),
  title={Generative modeling by estimating gradients of the data distribution},
  author={Song, Yang and Ermon, Stefano},
  journal={Advances in neural information processing systems},
  volume={32},
  year={2019},
  url={https://arxiv.org/abs/1907.05600},
}
    
@article{Song et al. (2023),
  title={Consistency models},
  author={Song, Yang and Dhariwal, Prafulla and Chen, Mark and Sutskever, Ilya},
  journal={arXiv preprint arXiv:2303.01469},
  year={2023},
  url={https://arxiv.org/abs/2303.01469},
}
    
@article{Ulyanov et al. (2016),
  title={Instance normalization: The missing ingredient for fast stylization},
  author={Ulyanov, Dmitry and Vedaldi, Andrea and Lempitsky, Victor},
  journal={arXiv preprint arXiv:1607.08022},
  year={2016},
  url={https://arxiv.org/abs/1607.08022},
}
    
@article{Vincent et al. (2010),
  title={Stacked denoising autoencoders: Learning useful representations in a deep network with a local denoising criterion.},
  author={Vincent, Pascal and Larochelle, Hugo and Lajoie, Isabelle and Bengio, Yoshua and Manzagol, Pierre-Antoine and Bottou, L{\'e}on},
  journal={Journal of machine learning research},
  volume={11},
  number={12},
  year={2010},
  url={https://www.jmlr.org/papers/volume11/vincent10a/vincent10a.pdf},
}
    
@inproceedings{Welling et al. (2011),
  title={Bayesian learning via stochastic gradient Langevin dynamics},
  author={Welling, Max and Teh, Yee W},
  booktitle={Proceedings of the 28th International Conference on Machine Learning (ICML-11)},
  pages={681--688},
  year={2011},
  url={https://www.stats.ox.ac.uk/~teh/research/compstats/WelTeh2011a.pdf},
}
    
@inproceedings{Wu et al. (2018),
  title={Group normalization},
  author={Wu, Yuxin and He, Kaiming},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018},
  url={https://arxiv.org/abs/1803.08494},
}    

@article{Yang et al. (2019),
  title={A mean field theory of batch normalization},
  author={Yang, Greg and Pennington, Jeffrey and Rao, Vinay and Sohl-Dickstein, Jascha and Schoenholz, Samuel S},
  journal={arXiv preprint arXiv:1902.08129},
  year={2019},
  url={https://arxiv.org/pdf/1902.08129},
}
    
@article{Zhang et al. (2019),
  title={Root mean square layer normalization},
  author={Zhang, Biao and Sennrich, Rico},
  journal={Advances in Neural Information Processing Systems},
  volume={32},
  year={2019},
  url={https://arxiv.org/pdf/1910.07467.pdf},
}

@online{Amortized Inference and Variational Auto Encoders,
  title={Amortized Inference and Variational Auto Encoders},
  url={https://erdogdu.github.io/csc412/notes/lec11-1.pdf},
  note="[accessed -]"
}

@online{Divergence,
  title={Divergence},
  url={https://en.wikipedia.org/wiki/Divergence_(statistics)},
  note="[accessed -]"
}

@online{Evidence Lower Bound,
  title={Evidence Lower Bound},
  url={https://en.wikipedia.org/wiki/Evidence_lower_bound},
  note="[accessed -]"
}

@online{KL Divergence,
  title={KL Divergence},
  url={https://en.wikipedia.org/wiki/Kullback%E2%80%93Leibler_divergence},
  note="[accessed -]"
}

@online{Lipschitz Continuity,
  title={Lipschitz Continuity},
  url={https://en.wikipedia.org/wiki/Lipschitz_continuity},
  note="[accessed - Oct 2023]"
}

@online{Markov kernel,
  title={Markov kernel},
  url={https://en.wikipedia.org/wiki/Markov_kernel},
  note="[accessed - Oct 2023]"
}

@online{Matrix Norm,
  title={Matrix Norm},
  url={https://en.wikipedia.org/wiki/Matrix_norm},
  note="[accessed - Oct 2023]"
}

@online{Stochastic Approximation,
  title={Stochastic Approximation},
  url={https://en.wikipedia.org/wiki/Stochastic_approximation},
  note="[accessed -]"
}

@online{The variational auto-encoder,
  title={The variational auto-encoder},
  url={https://ermongroup.github.io/cs228-notes/extras/vae},
  note="[accessed -]"
}

@online{Variational Inference with Normalizing Flows,
  title={Variational Inference with Normalizing Flows},
  url={https://www.depthfirstlearning.com/2021/VI-with-NFs},
  note="[accessed -]"
}

@online{Variational inference,
  title={Variational inference},
  url={https://ermongroup.github.io/cs228-notes/inference/variational},
  note="[accessed -]"
}

@online{Ari Seff Diffusion Models youtube,
  title = {What are Diffusion Models?},
  author={Ari Seff},
  url={https://www.youtube.com/watch?v=fbLgFrlTnGU},
  note="[video]"
}

@online{Variational Inference: Foundations and Innovations, 
  title={Variational Inference: Foundations and Innovations},
  author={David Blei},
  url={https://www.youtube.com/watch?v=Dv86zdWjJKQ},
  note="[video]"
}
